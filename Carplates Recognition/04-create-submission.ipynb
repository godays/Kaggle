{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as fnn\n",
    "import torchvision.models as models\n",
    "\n",
    "from detection import create_detection_model, DetectionDataset, Flip, PerspectiveTransform\n",
    "from recognition import CRNN, RecognitionDataset, beam_search, LanguageModel\n",
    "from detection_utils import PlateImageAdjuster, PlateImageExtractor\n",
    "from recognition_utils import Resize, collate_fn_recognition_test\n",
    "#from classifier import ClassifierDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [\n",
    "    (transforms.ToPILImage(), 'image'),\n",
    "    (transforms.ToTensor(), 'image'),\n",
    "                    ]\n",
    "\n",
    "test_dataset = DetectionDataset('data', transformations, 'test')\n",
    "\n",
    "test_dataloader = data.DataLoader(\n",
    "        test_dataset, batch_size=2,\n",
    "        num_workers=4, pin_memory=True,\n",
    "        shuffle=False, drop_last=False,\n",
    "        collate_fn=DetectionDataset.collate_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection model Loaded\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = create_detection_model()\n",
    "\n",
    "with open('SGD_lr_3e-4_plateau_best.pth', 'rb') as fp:\n",
    "    state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print('Detection model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1579/1579 [18:00<00:00,  1.46it/s] \n"
     ]
    }
   ],
   "source": [
    "THRESHOLD_MASK = 0.05\n",
    "THRESHOLD_BOX = 0.92\n",
    "\n",
    "path_test_ocr = Path('test_ocr_data')\n",
    "path_test_ocr.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "normalizer = PlateImageAdjuster()\n",
    "extractor = PlateImageExtractor()\n",
    "\n",
    "test_plates_filenames = []\n",
    "\n",
    "for i, batch in enumerate(tqdm.tqdm(test_dataloader)):\n",
    "    images = list(image.to(device) for image in batch[0])\n",
    "    filenames = list(filename['filename'] for filename in batch[1])\n",
    "    with torch.no_grad():\n",
    "        preds = model(images)\n",
    "    for pred, image_tensor, filename in zip(preds, images, filenames):\n",
    "        ps = pred['scores'].detach().cpu().numpy()\n",
    "        boxes = pred['boxes'].detach().cpu().numpy()\n",
    "        masks = (pred['masks'].detach().cpu().squeeze(1).numpy() > THRESHOLD_MASK).astype(np.uint8)\n",
    "        image = image_tensor.cpu().permute(1, 2, 0).numpy() * 255\n",
    "        sorted_triads = sorted(list(zip(ps, boxes, masks)), key = lambda x: x[1][0])\n",
    "        n = 0\n",
    "        for p, box, mask in sorted_triads:\n",
    "            if p > THRESHOLD_BOX:\n",
    "            # Too small images are useless\n",
    "                if (box[2] - box[0]) * (box[3] - box[1]) < 100:\n",
    "                    continue\n",
    "                plate_image = extractor(image, mask, box)\n",
    "                plate_image = normalizer(plate_image)\n",
    "                path = Path(filename)\n",
    "                plate_file_name = ''.join(['_'.join([path.stem, str(n)]), path.suffix])\n",
    "                cv2.imwrite(str(path_test_ocr / plate_file_name), plate_image)\n",
    "                test_plates_filenames.append(plate_file_name)\n",
    "\n",
    "                # Save bbox_image\n",
    "                bbox_image = image[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "                bbox_image_file_name = ''.join(['_'.join([path.stem, str(n), 'bbox']), path.suffix])\n",
    "                bbox_image = normalizer(bbox_image)\n",
    "                cv2.imwrite(str(path_test_ocr / bbox_image_file_name), bbox_image)\n",
    "                n += 1\n",
    "        if n == 0:\n",
    "            j = np.argmax(ps)\n",
    "            plate_image = extractor(image, masks[j], box[j])\n",
    "            plate_image = normalizer(plate_image)\n",
    "            path = Path(filename)\n",
    "            plate_file_name = ''.join(['_'.join([path.stem, str(n)]), path.suffix])\n",
    "            cv2.imwrite(str(path_test_ocr / plate_file_name), plate_image)\n",
    "            test_plates_filenames.append(plate_file_name)\n",
    "            \n",
    "            # Save bbox_image\n",
    "            bbox_image = image[int(boxes[j][1]):int(boxes[j][3]), int(boxes[j][0]):int(boxes[j][2])]\n",
    "            bbox_image_file_name = ''.join(['_'.join([path.stem, str(n), 'bbox']), path.suffix])\n",
    "            bbox_image = normalizer(bbox_image)\n",
    "            cv2.imwrite(str(path_test_ocr / bbox_image_file_name), bbox_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_test_ocr / 'test_plates_filenames.json', 'w') as f:\n",
    "    json.dump(test_plates_filenames, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "preds = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnn = CRNN(rnn_bidirectional=True)\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    Resize(),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "                    ])\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "test_ocr_dataset = RecognitionDataset('test_ocr_data', transformations, crnn.alphabet, 'test')\n",
    "test_ocr_dataloader = torch.utils.data.DataLoader(test_ocr_dataset, \n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=num_workers, pin_memory=True, \n",
    "                                                  drop_last=False, collate_fn=collate_fn_recognition_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition model Loaded\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "with open('Recognition_model_with_generated_test.pth', 'rb') as fp:\n",
    "    state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "crnn.load_state_dict(state_dict)\n",
    "crnn.to(device)\n",
    "crnn.eval()\n",
    "print('Recognition model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [08:24<00:00,  9.17s/it]\n"
     ]
    }
   ],
   "source": [
    "filenames_list = []\n",
    "text_pred = []\n",
    "text_conf = []\n",
    "confidence = []\n",
    "max_prob = []\n",
    "min_prob = []\n",
    "\n",
    "submission_preds = {}\n",
    "lm = LanguageModel()\n",
    "\n",
    "for batch in tqdm.tqdm(test_ocr_dataloader):\n",
    "    with torch.no_grad():\n",
    "        preds = crnn(batch['image'].to(device))\n",
    "        preds_bbox = crnn(batch['image_bbox'].to(device))\n",
    "    preds = preds + preds_bbox\n",
    "    probs = fnn.softmax(preds, dim=2)\n",
    "    preds_with_confidence = [beam_search(pred, crnn.alphabet, beam_width=20, lm=lm, alpha=0.3, beta=4) for pred in probs.permute(1, 0, 2).cpu().data.numpy()]\n",
    "    texts_pred = [a[0] for a in preds_with_confidence]\n",
    "    batch_confidence = [a.item() for a in probs.permute(1, 0, 2).std(dim=2).mean(dim=1)]\n",
    "    \n",
    "    filenames = batch['file_name']\n",
    "    for filename, text, conf_score in zip(filenames, texts_pred, batch_confidence):\n",
    "        test_file_name, num = filename.stem.split('_')\n",
    "        test_file_name = ''.join(['test/', test_file_name, filename.suffix])\n",
    "        if test_file_name not in submission_preds:\n",
    "            submission_preds[test_file_name] = {}\n",
    "        submission_preds[test_file_name][int(num)] = (text, conf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF_THRESHOLD = 0.201\n",
    "\n",
    "submission_dict = defaultdict(str)\n",
    "for key in submission_preds:\n",
    "    sorted_keys = sorted(submission_preds[key].keys())\n",
    "    if len(sorted_keys) > 1:\n",
    "        submission_dict[key] = ' '.join([submission_preds[key][k][0] \n",
    "                                             for k in sorted_keys if submission_preds[key][k][1] > CONF_THRESHOLD])\n",
    "    else:\n",
    "        submission_dict[key] = submission_preds[key][sorted_keys[0]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>plates_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/2962.jpg</td>\n",
       "      <td>X953PE150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/2399.bmp</td>\n",
       "      <td>P116HO35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/2348.bmp</td>\n",
       "      <td>E293BM35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/616.bmp</td>\n",
       "      <td>B390OK35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/343.jpg</td>\n",
       "      <td>P002PA57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>test/1363.jpg</td>\n",
       "      <td>X050KX64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>test/979.bmp</td>\n",
       "      <td>H896HH59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>test/2368.jpg</td>\n",
       "      <td>T745AB102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>test/2949.jpg</td>\n",
       "      <td>P111KY25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>test/57.jpg</td>\n",
       "      <td>K167BX75 K171KP75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name      plates_string\n",
       "0     test/2962.jpg          X953PE150\n",
       "1     test/2399.bmp           P116HO35\n",
       "2     test/2348.bmp           E293BM35\n",
       "3      test/616.bmp           B390OK35\n",
       "4      test/343.jpg           P002PA57\n",
       "...             ...                ...\n",
       "3152  test/1363.jpg           X050KX64\n",
       "3153   test/979.bmp           H896HH59\n",
       "3154  test/2368.jpg          T745AB102\n",
       "3155  test/2949.jpg           P111KY25\n",
       "3156    test/57.jpg  K167BX75 K171KP75\n",
       "\n",
       "[3157 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('submission.csv')\n",
    "submission['plates_string'] = submission.file_name.apply(lambda x: submission_dict[x])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>plates_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_name, plates_string]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission.plates_string == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>plates_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_name, plates_string]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission.plates_string.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('bidir_lm_with_conf_normalized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
